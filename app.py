import streamlit as st
import json
import os
from evaluator.text_analyzer import TextAnalyzer
from evaluator.scorer import SamhallScorer
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
def create_radar_chart(scores):
    categories = list(scores.keys())
    values = list(scores.values())
    
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=categories,
        fill='toself',
        name='ã‚¹ã‚­ãƒ«è©•ä¾¡'
    ))
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 2])),
        showlegend=False
    )
    return fig

def create_job_match_chart(job_matches):
    # ãƒãƒƒãƒãƒ³ã‚°ç‡ä¸Šä½ã‚’ã‚°ãƒ©ãƒ•åŒ–
    df = pd.DataFrame(job_matches)
    fig = px.bar(df, x='match_rate', y='job_name', orientation='h',
                 title="è·ç¨®ãƒãƒƒãƒãƒ³ã‚°ç‡",
                 labels={'match_rate': 'ãƒãƒƒãƒãƒ³ã‚°ç‡ (%)', 'job_name': 'è·ç¨®'})
    fig.update_layout(yaxis={'categoryorder':'total ascending'})
    return fig
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
import os

# ==========================================
# 1. ã‚°ãƒ©ãƒ•ä½œæˆæ©Ÿèƒ½ (æ—§ utils/visualizer.py)
# ==========================================
def create_radar_chart(scores):
    categories = list(scores.keys())
    values = list(scores.values())
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(r=values, theta=categories, fill='toself'))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 2])), showlegend=False)
    return fig

def create_job_match_chart(job_matches):
    df = pd.DataFrame(job_matches)
    fig = px.bar(df, x='match_rate', y='job_name', orientation='h', title="è·ç¨®ãƒãƒƒãƒãƒ³ã‚°ç‡")
    return fig

# ==========================================
# 2. ä¿å­˜æ©Ÿèƒ½ (æ—§ utils/database.py)
# ==========================================
def save_evaluation(data, filepath="data/evaluations.json"):
    if not os.path.exists("data"): os.makedirs("data")
    try:
        history = []
        if os.path.exists(filepath):
            with open(filepath, "r", encoding="utf-8") as f: history = json.load(f)
        history.append(data)
        with open(filepath, "w", encoding="utf-8") as f: json.dump(history, f, ensure_ascii=False, indent=4)
        return True
    except: return False

def load_evaluations(filepath="data/evaluations.json"):
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f: return json.load(f)
    return []

# ==========================================
# 3. ã“ã“ã‹ã‚‰ä¸‹ã«ã€å…ƒã® app.py ã® st.title ãªã©ãŒç¶šãã¾ã™
# ==========================================

st.set_page_config(page_title="Samhall AIè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

st.title("ğŸ¯ Samhall AIè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ24è·ç¨®å¯¾å¿œï¼‰")

st.markdown("""
### ğŸ“Œ æœ¬ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦
æœ¬ã‚¢ãƒ—ãƒªã¯ã€åŠ´åƒèƒ½åŠ›è©•ä¾¡ãƒ¡ã‚½ãƒƒãƒ‰**ã€ŒO-lysï¼ˆã‚ªãƒ¼ãƒªã‚¹ï¼‰ã€**ã®æŒ‡æ¨™ã«åŸºã¥ãã€å€‹äººã®ã€Œã§ãã‚‹ã“ã¨ã€ã‚’å¯è¦–åŒ–ã™ã‚‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚

* **ãƒ’ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã‚‹**: 15ã®è©•ä¾¡é …ç›®ã‹ã‚‰ã€24è·ç¨®ã¨ã®ãƒãƒƒãƒãƒ³ã‚°ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚
* **å‚è€ƒæŒ‡æ¨™**: ç‹¬è‡ªé–‹ç™ºã®ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚æ”¯æ´ã®æ–¹å‘æ€§ã‚’æ¤œè¨ã™ã‚‹ãŸã‚ã®å‚è€ƒã¨ã—ã¦ã”æ´»ç”¨ãã ã•ã„ã€‚

### ğŸ”’ å®‰å¿ƒãƒ»å®‰å…¨ã¸ã®å–ã‚Šçµ„ã¿
* **åŒ¿åã§åˆ†æ**: æ°åãªã©ã®å€‹äººæƒ…å ±ã¯åˆ†æã«ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚
* **å›ç­”æ–‡ã®ã¿ã‚’åˆ¤å®š**: èª²é¡Œã®ã€Œå›ç­”å†…å®¹ã€ã ã‘ã‚’å®‰å…¨ã«ã‚¹ã‚³ã‚¢åŒ–ã—ã¾ã™ã€‚
* **ãƒ‡ãƒ¼ã‚¿ã®ä¿è­·**: å…¥åŠ›å†…å®¹ãŒå¤–éƒ¨ã®AIå­¦ç¿’ã«åˆ©ç”¨ã•ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
""")

with st.sidebar:
    st.header("ğŸ“ åŸºæœ¬æƒ…å ±")
    name = st.text_input("æ°å", value="")
    age = st.number_input("å¹´é½¢", min_value=15, max_value=100, value=25)
    gender = st.selectbox("æ€§åˆ¥", ["ç”·æ€§", "å¥³æ€§", "ãã®ä»–"])
    disability_type = st.text_input("éšœå®³ç¨®åˆ¥", value="")

st.header("âœï¸ ãƒ†ã‚­ã‚¹ãƒˆèª²é¡Œ")

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“– èª­è§£ãƒ»ç†è§£", "âœï¸ æ–‡ç« ä½œæˆ", "ğŸ”¢ è¨ˆç®—ãƒ»è«–ç†", "ğŸ’¬ ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"])

text_responses = {}

with tab1:
    st.subheader("èª­è§£ãƒ»ç†è§£åŠ›")
    text_responses['reading'] = st.text_area(
        "ä»¥ä¸‹ã®æ–‡ç« ã‚’èª­ã‚“ã§ã€å†…å®¹ã‚’ç°¡å˜ã«èª¬æ˜ã—ã¦ãã ã•ã„ï¼š\n\nã€Œåƒãã“ã¨ã¯ã€åå…¥ã‚’å¾—ã‚‹ã ã‘ã§ãªãã€ç¤¾ä¼šã¨ã¤ãªãŒã‚Šã€è‡ªåˆ†ã®èƒ½åŠ›ã‚’ç™ºæ®ã™ã‚‹å ´ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚ã€",
        height=150
    )

with tab2:
    st.subheader("æ–‡ç« ä½œæˆåŠ›")
    text_responses['writing'] = st.text_area(
        "ã‚ãªãŸãŒæœ€è¿‘çµŒé¨“ã—ãŸè‰¯ã„ã“ã¨ã«ã¤ã„ã¦ã€3ã€œ5æ–‡ã§æ›¸ã„ã¦ãã ã•ã„ã€‚",
        height=150
    )

with tab3:
    st.subheader("è¨ˆç®—ãƒ»è«–ç†åŠ›")
    text_responses['calculation'] = st.text_area(
        "æ™‚çµ¦1,200å††ã§1æ—¥6æ™‚é–“ã€é€±5æ—¥åƒã„ãŸå ´åˆã®æœˆåï¼ˆ4é€±é–“ï¼‰ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚è¨ˆç®—éç¨‹ã‚‚æ›¸ã„ã¦ãã ã•ã„ã€‚",
        height=150
    )

with tab4:
    st.subheader("ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³")
    text_responses['communication'] = st.text_area(
        "è·å ´ã§å›°ã£ãŸã“ã¨ãŒã‚ã£ãŸæ™‚ã€ã©ã®ã‚ˆã†ã«å‘¨ã‚Šã®äººã«ç›¸è«‡ã—ã¾ã™ã‹ï¼Ÿ",
        height=150
    )

if st.button("ğŸš€ AIè©•ä¾¡ã‚’é–‹å§‹", type="primary"):
    if not name:
        st.error("æ°åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    elif not any(text_responses.values()):
        st.error("å°‘ãªãã¨ã‚‚1ã¤ã®èª²é¡Œã«å›ç­”ã—ã¦ãã ã•ã„")
    else:
        with st.spinner("AIè©•ä¾¡ä¸­...ï¼ˆ10ã€œ30ç§’ã‹ã‹ã‚Šã¾ã™ï¼‰"):
            try:
                # 1. AIåˆ†æã®å®Ÿè¡Œ
                analyzer = TextAnalyzer()
                text_scores = analyzer.analyze(text_responses)
                
                # 2. æœ€çµ‚ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
                final_scores = SamhallScorer.calculate_final_scores(text_scores)
                
                # 3. ã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’åˆã‚ã›ã¾ã—ãŸï¼‰
                with open('utils/job_database.json', 'r', encoding='utf-8') as f:
                    job_db = json.load(f)
                
                # 4. ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œ
                job_matches = SamhallScorer.match_jobs(final_scores, job_db)
                
                # 5. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¸ã®ä¿å­˜
                st.session_state['scores'] = final_scores
                st.session_state['job_matches'] = job_matches
                st.session_state['evaluated'] = True
                
                st.success("âœ… è©•ä¾¡å®Œäº†ï¼ä¸‹è¨˜ã®çµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
                
            except Exception as e:
                st.error(f"è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
if 'evaluated' in st.session_state and st.session_state['evaluated']:
    st.header("ğŸ“Š è©•ä¾¡çµæœ")
    
    res_tab1, res_tab2, res_tab3, res_tab4 = st.tabs(["ğŸ“ˆ ç·åˆè©•ä¾¡", "ğŸ” è©³ç´°åˆ†æ", "ğŸ’¼ æ¨å¥¨è·å‹™ï¼ˆ24è·ç¨®ï¼‰", "ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ"])
    
    with res_tab1:
        st.subheader("ç·åˆã‚¹ã‚³ã‚¢")
        scores = st.session_state['scores']
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.plotly_chart(create_radar_chart(scores), use_container_width=True)
        
        with col2:
            st.markdown("#### ã‚¹ã‚³ã‚¢ä¸€è¦§")
            for skill, score in scores.items():
                if score >= 1.5:
                    level = "ğŸŸ¢ é«˜ã„"
                elif score >= 0.6:
                    level = "ğŸŸ¡ è‰¯å¥½"
                else:
                    level = "ğŸ”´ é™å®šçš„"
                st.markdown(f"**{skill}**: {score:.2f} {level}")
    
    with res_tab2:
        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ")
        
        with open('data/evaluation_criteria.json', 'r', encoding='utf-8') as f:
            criteria = json.load(f)
        
        for category, info in criteria['categories'].items():
            st.markdown(f"### {category}")
            st.caption(info['description'])
            
            category_scores = {skill: scores[skill] for skill in info['skills'] if skill in scores}
            avg_score = sum(category_scores.values()) / len(category_scores) if category_scores else 0
            
            st.metric(label="ã‚«ãƒ†ã‚´ãƒªå¹³å‡", value=f"{avg_score:.2f}")
            
            for skill, score in category_scores.items():
                st.progress(score / 2.0, text=f"{skill}: {score:.2f}")
            
            st.divider()
    
    with res_tab3:
        st.subheader("æ¨å¥¨è·å‹™ãƒãƒƒãƒãƒ³ã‚°ï¼ˆ24è·ç¨®å¯¾å¿œï¼‰")
        
        job_matches = st.session_state['job_matches']
        
        with open('data/job_database.json', 'r', encoding='utf-8') as f:
            job_db = json.load(f)
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("#### ãƒ•ã‚£ãƒ«ã‚¿")
            
            all_categories = ["å…¨ã¦"] + list(job_db['job_categories'].values())
            selected_category = st.selectbox("è·ç¨®ã‚«ãƒ†ã‚´ãƒª", all_categories)
            
            min_match = st.slider("æœ€ä½ãƒãƒƒãƒãƒ³ã‚°ç‡ (%)", 0, 100, 50, 5)
        
        filtered_matches = job_matches
        
        if selected_category != "å…¨ã¦":
            category_key = [k for k, v in job_db['job_categories'].items() if v == selected_category][0]
            filtered_matches = [m for m in filtered_matches if m['job']['category'] == category_key]
        
        filtered_matches = [m for m in filtered_matches if m['match_rate'] >= min_match]
        
        with col2:
            if filtered_matches:
                st.markdown(f"#### ãƒãƒƒãƒãƒ³ã‚°ä¸Šä½è·ç¨®ï¼ˆ{len(filtered_matches)}ä»¶ï¼‰")
                
                top_10 = filtered_matches[:10]
                
                for i, match in enumerate(top_10, 1):
                    job = match['job']
                    match_rate = match['match_rate']
                    
                    with st.expander(f"{i}. {job['name']} - {match_rate:.1f}% ãƒãƒƒãƒ"):
                        st.markdown(f"**ã‚«ãƒ†ã‚´ãƒª**: {job_db['job_categories'][job['category']]}")
                        st.markdown(f"**èª¬æ˜**: {job['description']}")
                        st.markdown(f"**æƒ³å®šçµ¦ä¸**: {job['salary']}")
                        st.markdown(f"**ãƒãƒƒãƒãƒ³ã‚°ç‡**: {match_rate:.1f}%")
                        st.markdown(f"**å……è¶³ã‚¹ã‚­ãƒ«**: {match['matched_skills']}/{match['total_skills']}")
                        
                        st.markdown("##### å¿…è¦ã‚¹ã‚­ãƒ«ã¨è©•ä¾¡")
                        for skill, req_score in job['required_scores'].items():
                            user_score = scores.get(skill, 1.0)
                            status = "âœ…" if user_score >= req_score else "âš ï¸"
                            st.markdown(f"{status} {skill}: å¿…è¦{req_score:.1f} / è©•ä¾¡{user_score:.2f}")
                        
                        st.markdown(f"**ã‚µãƒãƒ¼ãƒˆä½“åˆ¶**: {job['support']}")
            else:
                st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è·ç¨®ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        
        st.markdown("---")
        st.markdown("#### ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ")
        
        category_stats = {}
        for match in job_matches:
            cat = job_db['job_categories'][match['job']['category']]
            if cat not in category_stats:
                category_stats[cat] = {'count': 0, 'avg_match': 0}
            category_stats[cat]['count'] += 1
            category_stats[cat]['avg_match'] += match['match_rate']
        
        for cat in category_stats:
            category_stats[cat]['avg_match'] /= category_stats[cat]['count']
        
        col1, col2, col3 = st.columns(3)
        
        for i, (cat, stats) in enumerate(category_stats.items()):
            with [col1, col2, col3][i % 3]:
                st.metric(
                    label=cat,
                    value=f"{stats['count']}è·ç¨®",
                    delta=f"å¹³å‡ {stats['avg_match']:.1f}%"
                )
    
    with res_tab4:
        st.subheader("è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ")
        
        st.markdown(f"""
        ### è©•ä¾¡å¯¾è±¡è€…æƒ…å ±
        - **æ°å**: {name}
        - **å¹´é½¢**: {age}
        - **æ€§åˆ¥**: {gender}
        - **éšœå®³ç¨®åˆ¥**: {disability_type}
        
        ### ç·åˆè©•ä¾¡ã‚µãƒãƒªãƒ¼
        - **è©•ä¾¡é …ç›®æ•°**: 15é …ç›®
        - **å¹³å‡ã‚¹ã‚³ã‚¢**: {sum(scores.values()) / len(scores):.2f}
        - **æœ€é«˜ã‚¹ã‚³ã‚¢**: {max(scores.values()):.2f} ({max(scores, key=scores.get)})
        - **æœ€ä½ã‚¹ã‚³ã‚¢**: {min(scores.values()):.2f} ({min(scores, key=scores.get)})
        
        ### æ¨å¥¨è·ç¨® Top 5
        """)
        
        for i, match in enumerate(job_matches[:5], 1):
            st.markdown(f"{i}. **{match['job']['name']}** - {match['match_rate']:.1f}% ãƒãƒƒãƒ")
        
        if st.button("ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆJSONï¼‰"):
            report_data = {
                'name': name,
                'age': age,
                'gender': gender,
                'disability_type': disability_type,
                'scores': scores,
                'top_jobs': [
                    {
                        'name': m['job']['name'],
                        'match_rate': m['match_rate']
                    }
                    for m in job_matches[:10]
                ]
            }
            st.download_button(
                label="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=json.dumps(report_data, ensure_ascii=False, indent=2),
                file_name=f"evaluation_{name}.json",
                mime="application/json"
            )

st.markdown("---")
st.caption("Â© 2024 Samhall AIè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ24è·ç¨®å¯¾å¿œç‰ˆï¼‰")
